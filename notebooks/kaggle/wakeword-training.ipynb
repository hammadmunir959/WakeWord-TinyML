{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# WakeWord - Audio Keyword Spotting Training\n",
                "\n",
                "Training a DS-CNN model for keyword spotting on Google Speech Commands dataset.\n",
                "\n",
                "**Features:**\n",
                "- MFCC feature extraction\n",
                "- Data augmentation\n",
                "- DS-CNN architecture (optimized for edge)\n",
                "- TFLite export with INT8 quantization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q librosa soundfile"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "import librosa\n",
                "from pathlib import Path\n",
                "from tqdm.notebook import tqdm\n",
                "import json\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "print(f\"TensorFlow: {tf.__version__}\")\n",
                "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## Configuration"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'sample_rate': 16000,\n",
                "    'duration': 1.0,\n",
                "    'n_mfcc': 40,\n",
                "    'n_fft': 512,\n",
                "    'hop_length': 160,\n",
                "    'n_mels': 80,\n",
                "    'fmin': 20,\n",
                "    'fmax': 8000,\n",
                "    'batch_size': 64,\n",
                "    'epochs': 50,\n",
                "    'learning_rate': 0.001,\n",
                "    'dropout': 0.3,\n",
                "}\n",
                "CLASSES = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
                "NUM_CLASSES = len(CLASSES) + 1  # + unknown (no silence since we dont have it)\n",
                "print(f\"Training on {len(CLASSES)} keywords + unknown = {NUM_CLASSES} classes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## Dataset Loading"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import urllib.request\n",
                "import tarfile\n",
                "\n",
                "url = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
                "DATA_PATH = '/kaggle/working/speech_commands'\n",
                "archive_path = '/kaggle/working/speech_commands.tar.gz'\n",
                "\n",
                "if not os.path.exists(DATA_PATH):\n",
                "    print('Downloading Speech Commands dataset...')\n",
                "    urllib.request.urlretrieve(url, archive_path)\n",
                "    os.makedirs(DATA_PATH, exist_ok=True)\n",
                "    print('Extracting...')\n",
                "    with tarfile.open(archive_path, 'r:gz') as tar:\n",
                "        tar.extractall(DATA_PATH)\n",
                "    print('Done!')\n",
                "print(f'Data path: {DATA_PATH}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_audio(path, sr=16000, duration=1.0):\n",
                "    audio, _ = librosa.load(path, sr=sr, duration=duration)\n",
                "    target_length = int(sr * duration)\n",
                "    if len(audio) < target_length:\n",
                "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
                "    else:\n",
                "        audio = audio[:target_length]\n",
                "    return audio\n",
                "\n",
                "def extract_mfcc(audio, sr=16000, n_mfcc=40, n_fft=512, hop_length=160, n_mels=80):\n",
                "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
                "    return mfccs.T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_file_list(data_path, classes, max_per_class=2000):\n",
                "    files, labels = [], []\n",
                "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
                "    class_to_idx['_unknown_'] = len(classes)\n",
                "    \n",
                "    for class_name in classes:\n",
                "        class_dir = Path(data_path) / class_name\n",
                "        if class_dir.exists():\n",
                "            class_files = list(class_dir.glob('*.wav'))[:max_per_class]\n",
                "            files.extend(class_files)\n",
                "            labels.extend([class_to_idx[class_name]] * len(class_files))\n",
                "    \n",
                "    all_dirs = [d for d in Path(data_path).iterdir() if d.is_dir()]\n",
                "    unknown_files = []\n",
                "    for d in all_dirs:\n",
                "        if d.name not in classes and not d.name.startswith('_'):\n",
                "            unknown_files.extend(list(d.glob('*.wav'))[:200])\n",
                "    np.random.shuffle(unknown_files)\n",
                "    files.extend(unknown_files[:max_per_class])\n",
                "    labels.extend([class_to_idx['_unknown_']] * min(len(unknown_files), max_per_class))\n",
                "    \n",
                "    print(f'Total files: {len(files)}')\n",
                "    return files, labels, class_to_idx\n",
                "\n",
                "files, labels, class_to_idx = get_file_list(DATA_PATH, CLASSES)\n",
                "idx_to_class = {v: k for k, v in class_to_idx.items()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_files(files, labels):\n",
                "    features, valid_labels = [], []\n",
                "    for f, label in tqdm(zip(files, labels), total=len(files)):\n",
                "        try:\n",
                "            audio = load_audio(str(f), CONFIG['sample_rate'], CONFIG['duration'])\n",
                "            mfcc = extract_mfcc(audio, CONFIG['sample_rate'], CONFIG['n_mfcc'], CONFIG['n_fft'], CONFIG['hop_length'], CONFIG['n_mels'])\n",
                "            features.append(mfcc)\n",
                "            valid_labels.append(label)\n",
                "        except: continue\n",
                "    return np.array(features), np.array(valid_labels)\n",
                "\n",
                "X, y = process_files(files, labels)\n",
                "print(f'Features: {X.shape}, Labels: {y.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
                "\n",
                "def normalize(X):\n",
                "    mean = np.mean(X, axis=(1, 2), keepdims=True)\n",
                "    std = np.std(X, axis=(1, 2), keepdims=True) + 1e-8\n",
                "    return (X - mean) / std\n",
                "\n",
                "X_train = normalize(X_train)[..., np.newaxis]\n",
                "X_val = normalize(X_val)[..., np.newaxis]\n",
                "X_test = normalize(X_test)[..., np.newaxis]\n",
                "print(f'Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## DS-CNN Model"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras import layers, Model\n",
                "\n",
                "def create_ds_cnn(input_shape, num_classes, dropout=0.3):\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    x = layers.Conv2D(64, (3, 3), padding='same', use_bias=False)(inputs)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.ReLU()(x)\n",
                "    \n",
                "    for filters in [64, 64, 128, 128]:\n",
                "        x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False)(x)\n",
                "        x = layers.BatchNormalization()(x)\n",
                "        x = layers.ReLU()(x)\n",
                "        x = layers.Conv2D(filters, (1, 1), padding='same', use_bias=False)(x)\n",
                "        x = layers.BatchNormalization()(x)\n",
                "        x = layers.ReLU()(x)\n",
                "        if filters <= 64:\n",
                "            x = layers.MaxPooling2D((2, 2))(x)\n",
                "    \n",
                "    x = layers.GlobalAveragePooling2D()(x)\n",
                "    x = layers.Dense(128)(x)\n",
                "    x = layers.ReLU()(x)\n",
                "    x = layers.Dropout(dropout)(x)\n",
                "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
                "    return Model(inputs, outputs, name='ds_cnn')\n",
                "\n",
                "model = create_ds_cnn(X_train.shape[1:], NUM_CLASSES, CONFIG['dropout'])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
                "\n",
                "model.compile(optimizer=Adam(learning_rate=CONFIG['learning_rate']), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "callbacks = [\n",
                "    ModelCheckpoint('/kaggle/working/best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
                "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
                "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
                "]\n",
                "\n",
                "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'], callbacks=callbacks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "axes[0].plot(history.history['loss'], label='Train')\n",
                "axes[0].plot(history.history['val_loss'], label='Val')\n",
                "axes[0].set_title('Loss')\n",
                "axes[0].legend()\n",
                "axes[1].plot(history.history['accuracy'], label='Train')\n",
                "axes[1].plot(history.history['val_accuracy'], label='Val')\n",
                "axes[1].set_title('Accuracy')\n",
                "axes[1].legend()\n",
                "plt.savefig('/kaggle/working/training_history.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
                "print(f'Test Loss: {test_loss:.4f}')\n",
                "print(f'Test Accuracy: {test_acc:.4f}')\n",
                "\n",
                "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
                "unique_labels = np.unique(np.concatenate([y_test, y_pred]))\n",
                "class_names = [idx_to_class[i] for i in unique_labels]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
                "tflite_model = converter.convert()\n",
                "with open('/kaggle/working/wakeword_float.tflite', 'wb') as f:\n",
                "    f.write(tflite_model)\n",
                "print(f'Float model: {len(tflite_model) / 1024:.2f} KB')\n",
                "\n",
                "def representative_dataset():\n",
                "    for i in range(min(500, len(X_train))):\n",
                "        yield [X_train[i:i+1].astype(np.float32)]\n",
                "\n",
                "converter_int8 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
                "converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n",
                "converter_int8.representative_dataset = representative_dataset\n",
                "converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
                "converter_int8.inference_input_type = tf.int8\n",
                "converter_int8.inference_output_type = tf.int8\n",
                "tflite_int8 = converter_int8.convert()\n",
                "with open('/kaggle/working/wakeword_int8.tflite', 'wb') as f:\n",
                "    f.write(tflite_int8)\n",
                "print(f'INT8 model: {len(tflite_int8) / 1024:.2f} KB')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "metadata = {\n",
                "    'classes': [idx_to_class[i] for i in range(NUM_CLASSES)],\n",
                "    'input_shape': list(X_train.shape[1:]),\n",
                "    'config': CONFIG,\n",
                "    'test_accuracy': float(test_acc),\n",
                "    'model_params': int(model.count_params()),\n",
                "    'tflite_float_kb': len(tflite_model) / 1024,\n",
                "    'tflite_int8_kb': len(tflite_int8) / 1024\n",
                "}\n",
                "with open('/kaggle/working/metadata.json', 'w') as f:\n",
                "    json.dump(metadata, f, indent=2)\n",
                "print('Saved metadata.json')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CLEANUP - Remove dataset to reduce output size\n",
                "import shutil\n",
                "if os.path.exists('/kaggle/working/speech_commands'):\n",
                "    shutil.rmtree('/kaggle/working/speech_commands')\n",
                "if os.path.exists('/kaggle/working/speech_commands.tar.gz'):\n",
                "    os.remove('/kaggle/working/speech_commands.tar.gz')\n",
                "\n",
                "print('Final output files:')\n",
                "for f in os.listdir('/kaggle/working'):\n",
                "    print(f'  {f}: {os.path.getsize(f\"/kaggle/working/{f}\") / 1024:.2f} KB')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
        "language_info": {"name": "python", "version": "3.10.0"}
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
